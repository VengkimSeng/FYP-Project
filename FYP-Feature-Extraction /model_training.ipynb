{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff9f304",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/socheata/Documents/FYP-Khmer-Classification/TF_IDF_Features/Selected_Features/train_features.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 160\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMODEL TRAINING AND EVALUATION COMPLETE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 154\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 154\u001b[0m     X_train, X_valid, y_train, y_valid, label_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     results \u001b[38;5;241m=\u001b[39m train_and_evaluate_models(X_train, X_valid, y_train, y_valid, label_encoder)\n\u001b[1;32m    156\u001b[0m     display_results(results, label_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m():\n\u001b[0;32m---> 17\u001b[0m     train_features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_features.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m csr_matrix(\n\u001b[1;32m     19\u001b[0m         (train_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], train_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m'\u001b[39m], train_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindptr\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     20\u001b[0m         shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(train_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     valid_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_features.npz\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/socheata/Documents/FYP-Khmer-Classification/TF_IDF_Features/Selected_Features/train_features.npz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_DIR = '/Users/socheata/Documents/FYP-Khmer-Classification/TF_IDF_Features/Selected_Features/'\n",
    "MODEL_DIR = '/Users/socheata/Documents/FYP-Khmer-Classification/Models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    train_features = np.load(os.path.join(OUTPUT_DIR, 'train_features.npz'))\n",
    "    X_train = csr_matrix(\n",
    "        (train_features['data'], train_features['indices'], train_features['indptr']),\n",
    "        shape=tuple(train_features['shape'])\n",
    "    )\n",
    "    valid_features = np.load(os.path.join(OUTPUT_DIR, 'valid_features.npz'))\n",
    "    X_valid = csr_matrix(\n",
    "        (valid_features['data'], valid_features['indices'], valid_features['indptr']),\n",
    "        shape=tuple(valid_features['shape'])\n",
    "    )\n",
    "    with open(os.path.join(OUTPUT_DIR, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    with open(os.path.join(OUTPUT_DIR, 'tfidf_training_metadata.pkl'), 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    # Recreate y values\n",
    "    PROCESSED_TEXTS_DIR = '/Users/socheata/Documents/FYP-Khmer-Classification/Preprocess_articles'\n",
    "    METADATA_PATH = '/Users/socheata/Documents/FYP-Khmer-Classification/orginal_articles/metadata.csv'\n",
    "    metadata_df = pd.read_csv(METADATA_PATH)\n",
    "    doc_categories = dict(zip(metadata_df['docId'], metadata_df['category']))\n",
    "    text_files = [f for f in os.listdir(PROCESSED_TEXTS_DIR) if f.endswith('.txt')]\n",
    "    document_texts, document_categories = [], []\n",
    "    for filename in text_files:\n",
    "        doc_id = os.path.splitext(filename)[0]\n",
    "        if doc_id not in doc_categories:\n",
    "            continue\n",
    "        with open(os.path.join(PROCESSED_TEXTS_DIR, filename), 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        document_texts.append(text)\n",
    "        document_categories.append(doc_categories[doc_id])\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_texts, valid_texts, train_categories, valid_categories = train_test_split(\n",
    "        document_texts, document_categories, test_size=0.3, random_state=42, stratify=document_categories\n",
    "    )\n",
    "    y_train = label_encoder.transform(train_categories)\n",
    "    y_valid = label_encoder.transform(valid_categories)\n",
    "    return X_train, X_valid, y_train, y_valid, label_encoder\n",
    "\n",
    "def train_and_evaluate_models(X_train, X_valid, y_train, y_valid, label_encoder):\n",
    "    class_names = label_encoder.classes_\n",
    "    results = {}\n",
    "    # MultinomialNB\n",
    "    best_alpha, best_accuracy = None, 0\n",
    "    for alpha in [0.01, 0.1, 0.5, 1.0]:\n",
    "        mnb = MultinomialNB(alpha=alpha)\n",
    "        mnb.fit(X_train, y_train)\n",
    "        accuracy = accuracy_score(y_valid, mnb.predict(X_valid))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_alpha = alpha\n",
    "    mnb = MultinomialNB(alpha=best_alpha)\n",
    "    mnb.fit(X_train, y_train)\n",
    "    y_pred_mnb = mnb.predict(X_valid)\n",
    "    accuracy_mnb = accuracy_score(y_valid, y_pred_mnb)\n",
    "    report_mnb = classification_report(y_valid, y_pred_mnb, target_names=class_names, output_dict=True)\n",
    "    cm_mnb = confusion_matrix(y_valid, y_pred_mnb)\n",
    "    results['mnb'] = {\n",
    "        'model': mnb, 'accuracy': accuracy_mnb, 'report': report_mnb,\n",
    "        'confusion_matrix': cm_mnb, 'y_pred': y_pred_mnb\n",
    "    }\n",
    "    with open(os.path.join(MODEL_DIR, 'mnb_model.pkl'), 'wb') as f:\n",
    "        pickle.dump(mnb, f)\n",
    "    # SVM\n",
    "    best_c, best_accuracy = None, 0\n",
    "    for c in [0.1, 1.0, 10.0]:\n",
    "        svm = LinearSVC(C=c, dual=False, max_iter=10000)\n",
    "        svm.fit(X_train, y_train)\n",
    "        accuracy = accuracy_score(y_valid, svm.predict(X_valid))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_c = c\n",
    "    svm = LinearSVC(C=best_c, dual=False, max_iter=10000)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_valid)\n",
    "    accuracy_svm = accuracy_score(y_valid, y_pred_svm)\n",
    "    report_svm = classification_report(y_valid, y_pred_svm, target_names=class_names, output_dict=True)\n",
    "    cm_svm = confusion_matrix(y_valid, y_pred_svm)\n",
    "    results['svm'] = {\n",
    "        'model': svm, 'accuracy': accuracy_svm, 'report': report_svm,\n",
    "        'confusion_matrix': cm_svm, 'y_pred': y_pred_svm\n",
    "    }\n",
    "    with open(os.path.join(MODEL_DIR, 'svm_model.pkl'), 'wb') as f:\n",
    "        pickle.dump(svm, f)\n",
    "    return results\n",
    "\n",
    "def display_results(results, class_names):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nAccuracy Comparison:\")\n",
    "    print(f\"MNB: {results['mnb']['accuracy']:.4f}\")\n",
    "    print(f\"SVM: {results['svm']['accuracy']:.4f}\")\n",
    "    print(\"\\nWeighted Average Metrics Comparison:\")\n",
    "    mnb_weighted = results['mnb']['report']['weighted avg']\n",
    "    svm_weighted = results['svm']['report']['weighted avg']\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    print(f\"{'Metric':<15} {'MNB':<10} {'SVM':<10}\")\n",
    "    print(\"-\"*35)\n",
    "    for metric in metrics:\n",
    "        print(f\"{metric:<15} {mnb_weighted[metric]:.4f}    {svm_weighted[metric]:.4f}\")\n",
    "    # Confusion matrices\n",
    "    plt.figure(figsize=(16, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(results['mnb']['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('MNB Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(results['svm']['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('SVM Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_DIR, 'confusion_matrices.png'))\n",
    "    plt.close()\n",
    "    # Per-class metrics\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        mnb_scores = [results['mnb']['report'][cls][metric] for cls in class_names]\n",
    "        svm_scores = [results['svm']['report'][cls][metric] for cls in class_names]\n",
    "        x = np.arange(len(class_names))\n",
    "        width = 0.35\n",
    "        plt.bar(x - width/2, mnb_scores, width, label='MNB')\n",
    "        plt.bar(x + width/2, svm_scores, width, label='SVM')\n",
    "        plt.xlabel('Categories')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.title(f'Per-Class {metric.capitalize()} Comparison')\n",
    "        plt.xticks(x, class_names, rotation=45)\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_DIR, 'metrics_comparison.png'))\n",
    "    plt.close()\n",
    "    print(\"Plots saved to Models directory.\")\n",
    "\n",
    "def main():\n",
    "    X_train, X_valid, y_train, y_valid, label_encoder = load_data()\n",
    "    results = train_and_evaluate_models(X_train, X_valid, y_train, y_valid, label_encoder)\n",
    "    display_results(results, label_encoder.classes_)\n",
    "    print(\"\\nMODEL TRAINING AND EVALUATION COMPLETE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58b3ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/socheata/Documents/FYP-Khmer-Classification/TF_IDF_Features/tfidf_training_metadata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     43\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m---> 44\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_labels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     45\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_labels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     47\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_labels'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
